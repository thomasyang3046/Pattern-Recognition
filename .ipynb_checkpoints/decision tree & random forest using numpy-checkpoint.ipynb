{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c40e420",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score # Please note that this is the only sklearn function that can be utilized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403dc139",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01704f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train/val/test dataset\n",
    "df_train = pd.DataFrame(pd.read_csv(\"./PR_HW3_Train.csv\"))\n",
    "df_val   = pd.DataFrame(pd.read_csv(\"./PR_HW3_Val.csv\"))\n",
    "df_test  = pd.DataFrame(pd.read_csv(\"./PR_HW3_Test.csv\"))\n",
    "\n",
    "X_train = df_train[['Feature1', 'Feature2', 'Feature3', 'Feature4', 'Feature5', 'Feature6', 'Feature7']].to_numpy()\n",
    "y_train = df_train[\"Target\"].to_numpy()\n",
    "\n",
    "X_val = df_val[['Feature1', 'Feature2', 'Feature3', 'Feature4', 'Feature5', 'Feature6', 'Feature7']].to_numpy()\n",
    "y_val = df_val[\"Target\"].to_numpy()\n",
    "\n",
    "X_test = df_test[['Feature1', 'Feature2', 'Feature3', 'Feature4', 'Feature5', 'Feature6', 'Feature7']].to_numpy()\n",
    "y_test = df_test[\"Target\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d436c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ad823c",
   "metadata": {},
   "source": [
    "Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ae2d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(sequence):\n",
    "    _, count=np.unique(sequence,return_counts=True)\n",
    "    p=count/len(sequence)\n",
    "    return 1-np.sum(p**2)\n",
    "\n",
    "\n",
    "def entropy(sequence):\n",
    "    _, count=np.unique(sequence,return_counts=True)\n",
    "    p=count/len(sequence)\n",
    "    return -1*np.sum(p*np.log(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06e999d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tree():\n",
    "    \"\"\"\n",
    "        You can add/change any variables/methods to meet your need.\n",
    "    \"\"\"\n",
    "    def __init__(self,feature_index=None,threshold=None,value=None,left_child=None,right_child=None):\n",
    "        self.feature_index = feature_index  # 該node要用哪個feature決定\n",
    "        self.threshold = threshold  # threshold value for feature split\n",
    "        self.value = value  # value if node is a leaf in the tree\n",
    "        self.left_child = left_child  # left subtree\n",
    "        self.right_child = right_child  # right subtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1927039d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree():\n",
    "    def __init__(self, criterion='gini', max_depth=None, max_features=None):\n",
    "        \n",
    "        \"\"\"\n",
    "            You can add/change any variables/methods to meet your need.\n",
    "        \"\"\"\n",
    "        #decide criterion\n",
    "        if criterion == 'gini':\n",
    "            self.criterion = gini\n",
    "        elif criterion == 'entropy':\n",
    "            self.criterion = entropy\n",
    "        #decide max depth of tree\n",
    "        if max_depth is None:\n",
    "            self.max_depth = 1e9\n",
    "        else:\n",
    "            self.max_depth = max_depth\n",
    "        self.max_features=max_features # 有多少features\n",
    "        self.tree=None #存最後的結果 best_feature & best_threshold\n",
    "        self.importance = {}\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        if self.max_features is None:\n",
    "            self.max_features=X.shape[1] #一共有多少features\n",
    "        self.importance=np.zeros(X.shape[1])   \n",
    "        self.tree=self.build_tree(X,y) #build tree\n",
    "    \n",
    "    def build_tree(self,X,y,depth=0):\n",
    "        n_sample,n_features=X.shape #n_sample=total數量, n_features=total feature數\n",
    "        n_classes=len(np.unique(y)) #有多少classes\n",
    "        \n",
    "        # Stop building tree if max_depth is reached\n",
    "        if self.max_depth and depth>=self.max_depth: \n",
    "            leaf_value=np.bincount(y.astype(int)).argmax()\n",
    "            return Tree(value=leaf_value)\n",
    "        # Stop building ree if there is only one class\n",
    "        if n_classes==1:\n",
    "            return Tree(value=y[0])\n",
    "        \n",
    "        # Find the best split\n",
    "        best_feature, best_threshold = self.best_split(X,y)\n",
    "        if best_threshold is None:\n",
    "            leaf_value=np.bincount(y.astype(int)).argmax()\n",
    "            return Tree(value=leaf_value)\n",
    "        left_indexs=X[:,best_feature]<best_threshold\n",
    "        right_indexs=X[:,best_feature]>=best_threshold\n",
    "        \n",
    "        # Stop building tree if there is no split\n",
    "        if len(left_indexs)==0 or len(right_indexs)==0:\n",
    "            leaf_value=np.bincount(y.astype(int)).argmax()\n",
    "            return Tree(value=leaf_value)\n",
    "        \n",
    "        # Build left and right subtrees\n",
    "        left_tree=self.build_tree(X[left_indexs],y[left_indexs],depth+1)\n",
    "        right_tree=self.build_tree(X[right_indexs],y[right_indexs],depth+1)\n",
    "        \n",
    "        # return the decision node\n",
    "        return Tree(feature_index=best_feature, threshold=best_threshold, left_child=left_tree, right_child=right_tree)\n",
    "    def best_split(self,X,y):\n",
    "        best_criterion=np.inf\n",
    "        best_feature,best_threshold=None,None\n",
    "        for feature in range(self.max_features):\n",
    "            thresholds=np.sort(X[:,feature], axis=-1, kind=None, order=None)\n",
    "            for i in range(1,X.shape[0]):\n",
    "                threshold=(thresholds[i-1]+thresholds[i])/2\n",
    "                left_indexs=X[:,feature]<threshold\n",
    "                right_indexs=X[:,feature]>= threshold\n",
    "                n_left=np.count_nonzero(left_indexs)\n",
    "                n_right=np.count_nonzero(right_indexs)\n",
    "                if n_left==0 or n_right==0:\n",
    "                    continue\n",
    "                # Calculate the criterion for the split\n",
    "                left_criterion=self.criterion(y[left_indexs])\n",
    "                right_criterion=self.criterion(y[right_indexs])\n",
    "                criterion=(n_left*left_criterion+n_right*right_criterion)/(n_left + n_right)\n",
    "                # Update best split\n",
    "                if criterion<best_criterion:\n",
    "                    best_criterion=criterion\n",
    "                    best_feature=feature\n",
    "                    best_threshold=threshold\n",
    "        return best_feature, best_threshold\n",
    "    def predict(self, X):\n",
    "        return [self.traverse(x) for x in X]\n",
    "    def traverse(self, x):\n",
    "        node = self.tree\n",
    "        while node.feature_index is not None:\n",
    "            if x[node.feature_index]<node.threshold:\n",
    "                node=node.left_child\n",
    "            else:\n",
    "                node=node.right_child\n",
    "        return node.value\n",
    "    def get_features(self,tree):\n",
    "        if tree.feature_index is not None:\n",
    "            self.get_features(tree.left_child)\n",
    "            self.importance[tree.feature_index]+=1     \n",
    "        if tree.feature_index is not None:\n",
    "            self.get_features(tree.right_child)\n",
    "            self.importance[tree.feature_index]+=1           \n",
    "    def countImportance(self):\n",
    "        self.importance=np.zeros(7).astype(int)  \n",
    "        node=self.tree\n",
    "        self.get_features(node)\n",
    "        return self.importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdbf77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest():\n",
    "    \"\"\"\n",
    "        You can add/change any variables/methods to meet your need.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_estimators=10, max_features=None, boostrap=True, criterion='gini', max_depth=None):\n",
    "        \n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_features = None\n",
    "        self.boostrap = boostrap\n",
    "        self.criterion = criterion\n",
    "        self.max_depth = max_depth\n",
    "        if max_features is None:\n",
    "            self.max_features=7\n",
    "        else:\n",
    "            self.max_features = int(round(max_features))\n",
    "        self.forest=[]\n",
    "        for i in range(self.n_estimators):\n",
    "            self.forest.append(DecisionTree(self.criterion,self.max_depth,self.max_depth))\n",
    "        self.random_features = []\n",
    "    def fit(self, X, y):\n",
    "        for i in range(self.n_estimators):\n",
    "            random_feature = np.random.choice(np.arange(X.shape[1]),size= self.max_features,replace=False)\n",
    "            self.random_features.append(random_feature)\n",
    "            if self.boostrap:\n",
    "                sample_num = int(np.round(X.shape[0]*2/3))\n",
    "                subset_index=np.random.choice(np.arange(X.shape[0]),size= sample_num,replace=False)\n",
    "                self.forest[i].fit(X[subset_index][:,random_feature],y[subset_index])\n",
    "            else:\n",
    "                self.forest[i].fit(X[:,random_feature],y)\n",
    "    def predict(self, X):\n",
    "        # majority vote\n",
    "        pred = np.zeros(X.shape[0]).astype(np.int32)\n",
    "        correct=0\n",
    "        for i in range(X.shape[0]):\n",
    "            vote=[]\n",
    "            for j in range(self.n_estimators):\n",
    "                vote.append(self.forest[j].traverse(X[i,self.random_features[j]]))\n",
    "            label, count= np.unique(vote, return_counts=True)\n",
    "            pred[i]=label[np.argmax(count)]\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d402e60",
   "metadata": {},
   "source": [
    "Questions for Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f823d584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Q1\n",
    "ex1 = np.array([\"+\", \"+\", \"+\", \"+\", \"+\", \"-\"])\n",
    "ex2 = np.array([\"+\", \"+\", \"+\", \"-\", \"-\", \"-\"])\n",
    "ex3 = np.array([\"+\" ,\"-\", \"-\", \"-\", \"-\", \"-\"])\n",
    "\n",
    "print(f\"{ex1}: entropy = {entropy(ex1)}\\n{ex2}: entropy = {entropy(ex2)}\\n{ex3}: entropy = {entropy(ex3)}\\n\")\n",
    "print(f\"{ex1}: gini index = {gini(ex1)}\\n{ex2}: gini index = {gini(ex2)}\\n{ex3}: gini index = {gini(ex3)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38558a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Q2-1, validation accuracy should be higher than or equal to 0.73\n",
    "\n",
    "np.random.seed(0) # You may adjust the seed number in all the cells\n",
    "\n",
    "dt_depth3 = DecisionTree(criterion='gini', max_features=None, max_depth=3)\n",
    "dt_depth3.fit(X_train, y_train)\n",
    "\n",
    "acc = accuracy_score(y_val, dt_depth3.predict(X_val))\n",
    "\n",
    "print(\"Q2-1 max_depth=3: \", acc)\n",
    "#3 5 3 3 6 2 2 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439b99f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Do Not Modify Below \"\"\"\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier as SK_DecisionTreeClassifier\n",
    "\n",
    "sk_dt = SK_DecisionTreeClassifier(criterion='gini', max_depth=3)\n",
    "sk_dt.fit(X_train, y_train)\n",
    "sk_acc = accuracy_score(y_val, sk_dt.predict(X_val))\n",
    "assert round(acc, 3) == round(sk_acc, 3), \"Because the Decision Tree without any trick has a fixed answer, your accuracy should be the same as sklearn, otherwise your implementation might have some problems\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae61a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Q2-2, validation accuracy should be higher than or equal to 0.85\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "dt_depth10 = DecisionTree(criterion='gini', max_features=None, max_depth=10)\n",
    "dt_depth10.fit(X_train, y_train)\n",
    "\n",
    "print(\"Q2-2 max_depth=10: \", accuracy_score(y_val,  dt_depth10.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33acb28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Q3-1, validation accuracy should be higher than or equal to 0.73\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "dt_gini = DecisionTree(criterion='gini', max_features=None, max_depth=3)\n",
    "dt_gini.fit(X_train, y_train)\n",
    "\n",
    "print(\"Q3-1 criterion='gini': \", accuracy_score(y_val, dt_gini.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792efe19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Q3-2, validation accuracy should be higher than or equal to 0.77\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "dt_entropy = DecisionTree(criterion='entropy', max_features=None, max_depth=3)\n",
    "dt_entropy.fit(X_train, y_train)\n",
    "\n",
    "print(\"Q3-2 criterion='entropy': \", accuracy_score(y_val, dt_entropy.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9dd059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Q4\n",
    "# Use simply counting to get the feature importance: dt_depth10.importance\n",
    "labelList=['Feature1', 'Feature2', 'Feature3', 'Feature4', 'Feature5', 'Feature6', 'Feature7']\n",
    "values=dt_depth10.countImportance()\n",
    "sorted_indexes = sorted(range(len(values)), key=lambda k: values[k], reverse=True)\n",
    "sorted_values = [values[i] for i in sorted_indexes]\n",
    "sorted_labels = [labelList[i] for i in sorted_indexes]\n",
    "plt.title('Feature Importance')\n",
    "plt.barh(range(len(values)), sorted_values[::-1])\n",
    "plt.yticks(range(len(values)), sorted_labels[::-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70269f2f",
   "metadata": {},
   "source": [
    "Questions for Random Rorest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18962e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Q6-1, validation accuracy should be higher than or equal to 0.88\n",
    "\n",
    "np.random.seed(7)\n",
    "\n",
    "rf_estimators10 = RandomForest(n_estimators=10, max_features=np.sqrt(X_train.shape[1]), boostrap=True, criterion='gini', max_depth=None)\n",
    "rf_estimators10.fit(X_train, y_train)\n",
    "\n",
    "print(\"Q6-1 n_estimators=10: \", accuracy_score(y_val, rf_estimators10.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cd6937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Q6-2, validation accuracy should be higher than or equal to 0.89\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "rf_estimators50 = RandomForest(n_estimators=50, max_features=np.sqrt(X_train.shape[1]), boostrap=True, criterion='gini', max_depth=None)\n",
    "rf_estimators50.fit(X_train, y_train)\n",
    "\n",
    "print(\"Q6-1 n_estimators=50: \", accuracy_score(y_val, rf_estimators50.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a0cfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Q7-1, validation accuracy should be higher than or equal to 0.88\n",
    "\n",
    "np.random.seed(7)\n",
    "\n",
    "rf_maxfeature_sqrt = RandomForest(n_estimators=10, max_features=np.sqrt(X_train.shape[1]), boostrap=True, criterion='gini', max_depth=None)\n",
    "rf_maxfeature_sqrt.fit(X_train, y_train)\n",
    "\n",
    "print(\"Q7-1 max_features='sqrt': \", accuracy_score(y_val,  rf_maxfeature_sqrt.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a485bc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Q7-2, validation accuracy should be higher than or equal to 0.86\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "rf_maxfeature_none = RandomForest(n_estimators=10, max_features=None, boostrap=True, criterion='gini', max_depth=None)\n",
    "rf_maxfeature_none.fit(X_train, y_train)\n",
    "\n",
    "print(\"Q7-1 max_features='All': \", accuracy_score(y_val, rf_maxfeature_none.predict(X_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fff60dd",
   "metadata": {},
   "source": [
    "Train your own model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deebf23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and train your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d220e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(pd.read_csv(\"./PR_HW3_Train.csv\"))\n",
    "df_val   = pd.DataFrame(pd.read_csv(\"./PR_HW3_Val.csv\"))\n",
    "df_test  = pd.DataFrame(pd.read_csv(\"./PR_HW3_Test.csv\"))\n",
    "df_vals  = pd.DataFrame(pd.read_csv(\"./PR_HW3_Val.csv\" ,nrows=200))\n",
    "#X_train = df_train[['Feature1', 'Feature2', 'Feature3', 'Feature4', 'Feature5', 'Feature6', 'Feature7']].to_numpy()\n",
    "#y_train = df_train[\"Target\"].to_numpy()\n",
    "\n",
    "X_val = df_val[['Feature1', 'Feature2', 'Feature3', 'Feature4', 'Feature5', 'Feature6', 'Feature7']].to_numpy()\n",
    "y_val = df_val[\"Target\"].to_numpy()\n",
    "\n",
    "X_test = df_test[['Feature1', 'Feature2', 'Feature3', 'Feature4', 'Feature5', 'Feature6', 'Feature7']].to_numpy()\n",
    "y_test = df_test[\"Target\"].to_numpy()\n",
    "\n",
    "merged_df = pd.concat([df_train, df_vals], ignore_index=True)\n",
    "\n",
    "X_train = merged_df[['Feature1', 'Feature2', 'Feature3', 'Feature4', 'Feature5', 'Feature6', 'Feature7']].to_numpy()\n",
    "y_train = merged_df[\"Target\"].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458f1916",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c7dbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(33)\n",
    "my_model = RandomForest(n_estimators=150, max_features=np.sqrt(X_train.shape[1]), boostrap=True, criterion='gini', max_depth=None)\n",
    "my_model.fit(X_train, y_train)\n",
    "print(\"n_estimators=150: \", accuracy_score(y_val,my_model.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d7382f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = my_model.predict(X_test)\n",
    "\n",
    "print(\"test_pred shape: \", test_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260d4002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output csv\n",
    "df_test = pd.DataFrame(pd.read_csv(\"./PR_HW3_Test.csv\"))\n",
    "df_test[\"Target\"] = test_pred\n",
    "df_test.to_csv(\"311553046_prediction2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73db5e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
